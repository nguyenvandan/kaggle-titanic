{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><h1 style=\"font-size:2em;color:#2467C0\">Predict survival on the Titanic and get familiar with ML basics</h1><br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import DataFrameNaFunctions\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer\n",
    "from pyspark.sql.functions import when, udf, col, collect_list\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data stored in CSV format as DataFrame.\n",
    "trainData = spark.read.format(\"org.apache.spark.csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").csv(\"data/train.csv\")\n",
    "testData = spark.read.format(\"org.apache.spark.csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").csv(\"data/test.csv\")\n",
    "submissionData = spark.read.format(\"org.apache.spark.csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").csv(\"data/gender_submission.csv\")\n",
    "testData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- SexInt: integer (nullable = false)\n",
      " |-- embarkedInt: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create new Int field \"SexInt\" based on the existing String field \"Sex\"\n",
    "# Sex \"Male\" = 1\n",
    "# Sex \"Female\" = 0\n",
    "newTrainData = trainData.withColumn('SexInt', \n",
    "                                    when(trainData.Sex == 'female', 0)\n",
    "                                    .otherwise(1)\n",
    "                                    )\n",
    "newTrainData = newTrainData.withColumn('embarkedInt', \n",
    "                                       when(newTrainData.Embarked == 'C', 0)\n",
    "                                       .when(newTrainData.Embarked == 'Q', 1)\n",
    "                                       .otherwise(2)\n",
    "                                      )\n",
    "                                      \n",
    "\n",
    "newTestData = testData.withColumn('SexInt', \n",
    "                                    when(testData.Sex == 'female', 0)\n",
    "                                    .otherwise(1)\n",
    "                                    )\n",
    "newTestData = newTestData.withColumn('embarkedInt', \n",
    "                                       when(newTestData.Embarked == 'C', 0)\n",
    "                                       .when(newTestData.Embarked == 'Q', 1)\n",
    "                                       .otherwise(2)\n",
    "                                      )\n",
    "newTrainData.printSchema()\n",
    "#newTrainData.show(5)\n",
    "#newTestData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process test data\n",
    "# extract Mr, Mrs, Miss, Master\n",
    "newTestData = newTestData.withColumn('title', \n",
    "                                     when(col('Name').like('%Master.%'), 'Master.')\n",
    "                                     .when(col('Name').like('%Miss.%')\n",
    "                                           | col('Name').like('%Mlle.%')\n",
    "                                           | col('Name').like('%Ms.%'), 'Miss.')\n",
    "                                     .when(col('Name').like('%Mrs.%') \n",
    "                                           | col('Name').like('%Mme.%')\n",
    "                                           | col('Name').like('%Lady.%'), 'Mrs.')\n",
    "                                     .when(col('Name').like('%Mr.%') \n",
    "                                           | col('Name').like('%Sir.%')\n",
    "                                           | col('Name').like('%Major.%'), 'Mr.')\n",
    "                                     .when(col('Name').like('%Rev.%'), 'Rev.')    \n",
    "                                     .when(col('Name').like('%Dr.%'), 'Dr.')                                     \n",
    "                                     .otherwise('Unknown.')\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median age\n",
    "def median(values_list):\n",
    "    med = np.median(values_list)\n",
    "    return float(med)\n",
    "\n",
    "udf_median = udf(median, FloatType())\n",
    "#group_newTestData = newTestData.groupby(['title'])\n",
    "#df_grouped = group_newTestData.agg(udf_median(collect_list(col('Age'))).alias('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#group_df = df.groupby(['a', 'd'])\n",
    "#df_grouped = group_df.agg(udf_median(func.collect_list(col('c'))).alias('median'))\n",
    "#df_grouped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>418</td>\n",
       "      <td>1100.5</td>\n",
       "      <td>120.81045760473994</td>\n",
       "      <td>892</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>418</td>\n",
       "      <td>2.2655502392344498</td>\n",
       "      <td>0.8418375519640503</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <td>418</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>\"Assaf Khalil, Mrs. Mariana (Miriam\"\")\"\"\"</td>\n",
       "      <td>van Billiard, Master. Walter John</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>418</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>female</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>332</td>\n",
       "      <td>30.272590361445783</td>\n",
       "      <td>14.181209235624424</td>\n",
       "      <td>0.17</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp</th>\n",
       "      <td>418</td>\n",
       "      <td>0.4473684210526316</td>\n",
       "      <td>0.8967595611217135</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch</th>\n",
       "      <td>418</td>\n",
       "      <td>0.3923444976076555</td>\n",
       "      <td>0.9814288785371694</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>418</td>\n",
       "      <td>223850.98986486485</td>\n",
       "      <td>369523.7764694362</td>\n",
       "      <td>110469</td>\n",
       "      <td>W.E.P. 5734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>417</td>\n",
       "      <td>35.6271884892086</td>\n",
       "      <td>55.907576179973844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>512.3292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>91</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>A11</td>\n",
       "      <td>G6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>418</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SexInt</th>\n",
       "      <td>418</td>\n",
       "      <td>0.6363636363636364</td>\n",
       "      <td>0.481622140932231</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embarkedInt</th>\n",
       "      <td>418</td>\n",
       "      <td>1.4019138755980862</td>\n",
       "      <td>0.8544964564020433</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>418</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Dr.</td>\n",
       "      <td>Unknown.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                   1                   2  \\\n",
       "summary      count                mean              stddev   \n",
       "PassengerId    418              1100.5  120.81045760473994   \n",
       "Pclass         418  2.2655502392344498  0.8418375519640503   \n",
       "Name           418                None                None   \n",
       "Sex            418                None                None   \n",
       "Age            332  30.272590361445783  14.181209235624424   \n",
       "SibSp          418  0.4473684210526316  0.8967595611217135   \n",
       "Parch          418  0.3923444976076555  0.9814288785371694   \n",
       "Ticket         418  223850.98986486485   369523.7764694362   \n",
       "Fare           417    35.6271884892086  55.907576179973844   \n",
       "Cabin           91                None                None   \n",
       "Embarked       418                None                None   \n",
       "SexInt         418  0.6363636363636364   0.481622140932231   \n",
       "embarkedInt    418  1.4019138755980862  0.8544964564020433   \n",
       "title          418                None                None   \n",
       "\n",
       "                                                     3  \\\n",
       "summary                                            min   \n",
       "PassengerId                                        892   \n",
       "Pclass                                               1   \n",
       "Name         \"Assaf Khalil, Mrs. Mariana (Miriam\"\")\"\"\"   \n",
       "Sex                                             female   \n",
       "Age                                               0.17   \n",
       "SibSp                                                0   \n",
       "Parch                                                0   \n",
       "Ticket                                          110469   \n",
       "Fare                                               0.0   \n",
       "Cabin                                              A11   \n",
       "Embarked                                             C   \n",
       "SexInt                                               0   \n",
       "embarkedInt                                          0   \n",
       "title                                              Dr.   \n",
       "\n",
       "                                             4  \n",
       "summary                                    max  \n",
       "PassengerId                               1309  \n",
       "Pclass                                       3  \n",
       "Name         van Billiard, Master. Walter John  \n",
       "Sex                                       male  \n",
       "Age                                       76.0  \n",
       "SibSp                                        8  \n",
       "Parch                                        9  \n",
       "Ticket                             W.E.P. 5734  \n",
       "Fare                                  512.3292  \n",
       "Cabin                                       G6  \n",
       "Embarked                                     S  \n",
       "SexInt                                       1  \n",
       "embarkedInt                                  2  \n",
       "title                                 Unknown.  "
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newTestData.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "featureColumns = ['Pclass', 'SexInt', 'SibSp', 'Parch', 'embarkedInt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- SexInt: integer (nullable = false)\n",
      " |-- embarkedInt: integer (nullable = false)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete non useful fields\n",
    "newTrainData = newTrainData.drop('Cabin', 'Ticket', 'PassengerId')\n",
    "newTestData = newTestData.drop('Cabin', 'Ticket')\n",
    "newTrainData = newTrainData.na.drop()\n",
    "newTestData = newTestData.na.drop()\n",
    "newTrainData.printSchema()\n",
    "newTestData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=featureColumns, outputCol=\"features\")\n",
    "assembledTrainData = assembler.transform(newTrainData)\n",
    "assembledTestData = assembler.transform(newTestData)\n",
    "assembledTrainData.count()\n",
    "assembledTestData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"Survived\", outputCol=\"indexedLabel\").fit(assembledTrainData)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(assembledTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline = Pipeline(stages=[dt])\n",
    "#model = pipeline.fit(assembled)\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(assembledTrainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(assembledTestData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- SexInt: integer (nullable = false)\n",
      " |-- embarkedInt: integer (nullable = false)\n",
      " |-- title: string (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- indexedFeatures: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "'path file:/home/vdnguyen/kaggle/kaggle-titanic/mycsv.csv already exists.;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/home/vdnguyen/spark/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vdnguyen/spark/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o7447.csv.\n: org.apache.spark.sql.AnalysisException: path file:/home/vdnguyen/kaggle/kaggle-titanic/mycsv.csv already exists.;\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:80)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:58)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:56)\n\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.doExecute(commands.scala:74)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:114)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:135)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:132)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:113)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:92)\n\tat org.apache.spark.sql.execution.datasources.DataSource.writeInFileFormat(DataSource.scala:484)\n\tat org.apache.spark.sql.execution.datasources.DataSource.write(DataSource.scala:520)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:215)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:198)\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:579)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-577-134da2f2ac62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmissionData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PassengerId\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"prediction\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mycsv.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/vdnguyen/spark/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat)\u001b[0m\n\u001b[1;32m    709\u001b[0m                        \u001b[0mnullValue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnullValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mescapeQuotes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mescapeQuotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoteAll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquoteAll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                        dateFormat=dateFormat, timestampFormat=timestampFormat)\n\u001b[0;32m--> 711\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vdnguyen/spark/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/vdnguyen/spark/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'path file:/home/vdnguyen/kaggle/kaggle-titanic/mycsv.csv already exists.;'"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()\n",
    "predictions.count(), submissionData.count()\n",
    "predictions.select(\"PassengerId\", \"prediction\").write.csv('mycsv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractedPredictions = predictions.select(\"PassengerId\", \"prediction\")\n",
    "output = submissionData.join(extractedPredictions,['PassengerId'],\"inner\")\n",
    "predictionAndLabels = output.select(\"prediction\", \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictionAndLabels)\n",
    "print(\"Test accuracy = %g \" % (accuracy))\n",
    "\n",
    "treeModel = model.stages[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic_3",
   "language": "python",
   "name": "titanic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
